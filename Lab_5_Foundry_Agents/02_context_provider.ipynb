{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-1",
   "metadata": {},
   "source": "# Introduction to Context Providers\n\nIn the previous notebook, you built an agent that uses **tools** — functions the agent explicitly decides to call. In this notebook, you'll learn about **context providers**, MAF's mechanism for automatically injecting context before each agent invocation.\n\n## Tools vs Context Providers\n\n| | Tools | Context Providers |\n|---|---|---|\n| **When they run** | Only when the agent decides to call them | Automatically before **every** agent invocation |\n| **How they work** | Agent sees function name + docstring, decides to call | `before_run()` injects instructions/messages into `SessionContext` |\n| **Best for** | On-demand actions (lookups, API calls) | Always-available background knowledge (RAG, memory, user preferences) |\n\n## Context Provider Lifecycle\n\nContext providers have two lifecycle hooks that run around each agent invocation:\n\n```\nagent.run(query)\n    │\n    ├── before_run()  ← Inject context into SessionContext\n    │       • context.extend_instructions()  — add to system prompt\n    │       • context.extend_messages()       — add messages to context\n    │       • context.extend_tools()          — dynamically add tools\n    │\n    ├── LLM processes query + injected context\n    │\n    └── after_run()   ← Process the response\n            • Extract structured data from the conversation\n            • Store information in session.state for next turn\n```\n\n## What You'll Build\n\nA `UserInfoMemory` context provider that:\n- **`before_run()`** — Injects dynamic instructions based on what it knows about the user\n- **`after_run()`** — Extracts structured data (name, age) from the conversation using the LLM\n\nNo external services are needed beyond the LLM. In Lab 6, you'll use the same pattern with `Neo4jContextProvider` to inject knowledge graph results.\n\n***"
  },
  {
   "cell_type": "markdown",
   "id": "setup-md",
   "metadata": {},
   "source": [
    "Load the environment variables and import the required Python modules."
   ]
  },
  {
   "cell_type": "code",
   "id": "setup-code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "import sys\nsys.path.insert(0, '../shared')\n\nfrom typing import Any\n\nfrom agent_framework import (\n    AgentSession,\n    BaseContextProvider,\n    SessionContext,\n    SupportsChatGetResponse,\n)\nfrom agent_framework.azure import AzureOpenAIResponsesClient\nfrom azure.identity import AzureCliCredential\nfrom pydantic import BaseModel\n\nfrom config import get_agent_config"
  },
  {
   "cell_type": "markdown",
   "id": "config-md",
   "metadata": {},
   "source": [
    "Get the agent configuration from the environment."
   ]
  },
  {
   "cell_type": "code",
   "id": "config-code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = get_agent_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-md",
   "metadata": {},
   "source": [
    "## Define the Data Model\n",
    "\n",
    "Define a Pydantic model for the structured data the context provider will extract. The LLM will use this schema to return structured output."
   ]
  },
  {
   "cell_type": "code",
   "id": "model-code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "class UserInfo(BaseModel):\n",
    "    name: str | None = None\n",
    "    age: int | None = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provider-md",
   "metadata": {},
   "source": "## Define the Context Provider\n\nCreate a `UserInfoMemory` context provider that inherits from `BaseContextProvider`.\n\nThe two key methods are:\n\n- **`before_run()`** — Called before each agent invocation. Receives the `SessionContext` and uses `context.extend_instructions()` to inject dynamic instructions based on what it knows about the user.\n- **`after_run()`** — Called after each agent invocation. Uses `context.get_messages()` to read the conversation, then makes a structured LLM call to extract the user's name and age.\n\nState is stored in `session.state[\"user-info-memory\"]` — a persistent dictionary that survives across conversation turns. Each context provider gets its own namespace in this state dict via `self.source_id`."
  },
  {
   "cell_type": "code",
   "id": "provider-code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "class UserInfoMemory(BaseContextProvider):\n",
    "    \"\"\"Context provider that extracts and remembers user info (name, age).\"\"\"\n",
    "\n",
    "    def __init__(self, client: SupportsChatGetResponse):\n",
    "        super().__init__(\"user-info-memory\")\n",
    "        self._chat_client = client\n",
    "\n",
    "    async def before_run(\n",
    "        self,\n",
    "        *,\n",
    "        agent: Any,\n",
    "        session: AgentSession | None,\n",
    "        context: SessionContext,\n",
    "        state: dict[str, Any],\n",
    "    ) -> None:\n",
    "        \"\"\"Inject dynamic instructions based on stored user info.\"\"\"\n",
    "        my_state = state.setdefault(self.source_id, {})\n",
    "        user_info = my_state.setdefault(\"user_info\", UserInfo())\n",
    "\n",
    "        instructions: list[str] = []\n",
    "\n",
    "        if user_info.name is None:\n",
    "            instructions.append(\n",
    "                \"Ask the user for their name and politely decline to answer any questions until they provide it.\"\n",
    "            )\n",
    "        else:\n",
    "            instructions.append(f\"The user's name is {user_info.name}.\")\n",
    "\n",
    "        if user_info.age is None:\n",
    "            instructions.append(\n",
    "                \"Ask the user for their age and politely decline to answer any questions until they provide it.\"\n",
    "            )\n",
    "        else:\n",
    "            instructions.append(f\"The user's age is {user_info.age}.\")\n",
    "\n",
    "        context.extend_instructions(self.source_id, \" \".join(instructions))\n",
    "\n",
    "    async def after_run(\n",
    "        self,\n",
    "        *,\n",
    "        agent: Any,\n",
    "        session: AgentSession | None,\n",
    "        context: SessionContext,\n",
    "        state: dict[str, Any],\n",
    "    ) -> None:\n",
    "        \"\"\"Extract user info from the conversation after each turn.\"\"\"\n",
    "        my_state = state.setdefault(self.source_id, {})\n",
    "        user_info = my_state.setdefault(\"user_info\", UserInfo())\n",
    "        if user_info.name is not None and user_info.age is not None:\n",
    "            return  # Already have everything\n",
    "\n",
    "        request_messages = context.get_messages(include_input=True, include_response=True)\n",
    "        user_messages = [\n",
    "            msg for msg in request_messages\n",
    "            if hasattr(msg, \"role\") and msg.role == \"user\"\n",
    "        ]\n",
    "        if not user_messages:\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            result = await self._chat_client.get_response(\n",
    "                messages=request_messages,\n",
    "                instructions=\"Extract the user's name and age from the message if present. \"\n",
    "                \"If not present return nulls.\",\n",
    "                options={\"response_format\": UserInfo},\n",
    "            )\n",
    "            extracted = result.value\n",
    "            if extracted and user_info.name is None and extracted.name:\n",
    "                user_info.name = extracted.name\n",
    "            if extracted and user_info.age is None and extracted.age:\n",
    "                user_info.age = extracted.age\n",
    "            state.setdefault(self.source_id, {})[\"user_info\"] = user_info\n",
    "        except Exception:\n",
    "            pass  # Failed to extract, continue without updating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-md",
   "metadata": {},
   "source": "> Notice how the context provider uses `context.extend_instructions()` to dynamically modify the agent's behavior each turn — this is the same mechanism that Neo4j context providers use in Lab 6 to inject knowledge graph results.\n\n***\n\n## Create the Agent\n\nCreate an agent with the `UserInfoMemory` context provider. The agent doesn't need any tools — the provider handles information extraction automatically."
  },
  {
   "cell_type": "code",
   "id": "agent-code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "credential = AzureCliCredential()\nclient = AzureOpenAIResponsesClient(\n    project_endpoint=config.project_endpoint,\n    deployment_name=config.model_name,\n    credential=credential,\n)\n\nagent = client.as_agent(\n    name=\"workshop-context-provider-agent\",\n    instructions=\"You are a friendly assistant. Always address the user by their name when you know it.\",\n    context_providers=[UserInfoMemory(client)],\n)\n\nsession = agent.create_session()\n\nasync def ask(query):\n    \"\"\"Run a query against the agent and print the response.\"\"\"\n    print(f\"User: {query}\\n\")\n    print(\"Assistant: \", end=\"\", flush=True)\n    response = await agent.run(query, session=session)\n    print(response.text)\n    print()\n\nprint(f\"Agent '{agent.name}' created\")"
  },
  {
   "cell_type": "markdown",
   "id": "convo-md",
   "metadata": {},
   "source": [
    "## Multi-Turn Conversation\n",
    "\n",
    "Run the cells below to see the context provider in action. Watch how the agent's behavior changes as it learns about the user.\n",
    "\n",
    "**Turn 1** — The provider has no user info yet, so it injects instructions to ask for the user's name and age."
   ]
  },
  {
   "cell_type": "code",
   "id": "turn-1",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "await ask(\"Hello, what is the square root of 9?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turn2-md",
   "metadata": {},
   "source": [
    "**Turn 2** — The user provides their name. After this turn, `after_run()` extracts it using structured LLM output."
   ]
  },
  {
   "cell_type": "code",
   "id": "turn-2",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "await ask(\"My name is Alex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turn3-md",
   "metadata": {},
   "source": [
    "**Turn 3** — The user provides their age. The provider now has all the information it needs."
   ]
  },
  {
   "cell_type": "code",
   "id": "turn-3",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "await ask(\"I am 30 years old\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turn4-md",
   "metadata": {},
   "source": [
    "**Turn 4** — Now that the provider knows the user, it injects their name and age as instructions. The agent can answer freely and uses the user's name."
   ]
  },
  {
   "cell_type": "code",
   "id": "turn-4",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "await ask(\"Now, what is the square root of 9?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "state-md",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Inspect Session State\n",
    "\n",
    "The context provider stores extracted data in `session.state`. This state persists across turns and can be serialized for long-term storage."
   ]
  },
  {
   "cell_type": "code",
   "id": "state-code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_info = session.state.get(\"user-info-memory\", {}).get(\"user_info\", UserInfo())\n",
    "print(f\"Extracted Name: {user_info.name}\")\n",
    "print(f\"Extracted Age: {user_info.age}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-md",
   "metadata": {},
   "source": [
    "> The context provider automatically extracted structured data from the conversation — without the agent needing to call any tools. In Lab 6, you'll use this same pattern with `Neo4jContextProvider` to automatically inject knowledge graph context before each agent invocation.\n",
    "\n",
    "***\n",
    "\n",
    "[Continue to Lab 6 - MAF Context Providers](../Lab_6_Context_Providers)"
   ]
  },
  {
   "cell_type": "code",
   "id": "cleanup-code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# No cleanup needed — AzureOpenAIResponsesClient and sync credentials\n# don't require explicit lifecycle management"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}